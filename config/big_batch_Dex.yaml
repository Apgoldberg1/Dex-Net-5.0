# big_batch_Dex.yaml

name: "BigBatchDexNet3"
optimizer:
  name: "SGD"
  learning_rate: 0.02
  momentum: .9
  scheduler_gamma: .90   #original: .95, but orig does every .66 epoch
  weight_decay: .0005
training:
  dataset_path: "dataset/dexnet_3/dexnet_09_13_17"
  batch_size: 256
  num_epochs: 25
  num_files: 2500
  resize: false
  GT_threshold: 0.2
  wandb: true
outputs:
  save_directory: "outputs/DexNet3"
  save_name: "big_batch_Dex"
  training_print_every: 50
  val_print_every: 100
  save_every_x_epoch: 10

  

