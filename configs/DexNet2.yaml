# parallel jaw config
name: "DexNet2"
model: "DexNetBase"
dataset: "dexnet2"
optimizer:
  name: "adam"
  learning_rate: 0.001
  momentum: .9
  scheduler_gamma: 1
  weight_decay: 0
training:
  dataset_path: "dataset/dexnet_2/dexnet_2_tensor"
  batch_size: 256
  num_epochs: 25
  resize: false
  GT_threshold: 0.2
  wandb: true
  ordered_split: true
  pos_weight: 1 # make 1 for no oversampling
outputs:
  save_directory: "outputs/parallel_jaw_models"
  save_name: "pj_dexnetbase_adam"
  training_print_every: 500
  val_print_every: 2000
  save_every_x_epoch: 10

  

